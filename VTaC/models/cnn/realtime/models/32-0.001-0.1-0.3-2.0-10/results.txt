C:\Users\harid\projects\cavn\VTaC\models\cnn\realtime\train.py
{'framework': 'textcnn', 'differ_loss_weight': 0.1, 'weighted_class': 2.0, 'learning_rate': 0.001, 'adam_weight_decay': 0.005, 'batch_size': 32, 'max_epoch': 10, 'data_length': 2500}
Training samples: 4060, Validation: 495, Test: 482
Positive samples - Train: 1163.0, Val: 141.0, Test: 137.0
Training samples: 4060, Validation: 495, Test: 482
Positive samples - Train: 1163.0, Val: 141.0, Test: 137.0
CNNClassifier(
  (convs): ModuleList(
    (0): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Conv1d(4, 64, kernel_size=(25,), stride=(5,), padding=(1,))
      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU()
      (4): Conv1d(64, 64, kernel_size=(25,), stride=(5,), padding=(1,))
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): AdaptiveMaxPool1d(output_size=1)
    )
    (1): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Conv1d(4, 64, kernel_size=(50,), stride=(5,), padding=(1,))
      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU()
      (4): Conv1d(64, 64, kernel_size=(50,), stride=(5,), padding=(1,))
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): AdaptiveMaxPool1d(output_size=1)
    )
    (2): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Conv1d(4, 64, kernel_size=(100,), stride=(5,), padding=(1,))
      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU()
      (4): Conv1d(64, 64, kernel_size=(100,), stride=(5,), padding=(1,))
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): AdaptiveMaxPool1d(output_size=1)
    )
    (3): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Conv1d(4, 64, kernel_size=(150,), stride=(5,), padding=(1,))
      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU()
      (4): Conv1d(64, 64, kernel_size=(150,), stride=(5,), padding=(1,))
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): AdaptiveMaxPool1d(output_size=1)
    )
  )
  (signal_feature): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (rule_based_label): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (classifier): Sequential(
    (0): Dropout(p=0.3, inplace=False)
    (1): Linear(in_features=128, out_features=1, bias=True)
  )
)
Num of Parameters: 1.449473M
NaN/Inf gradients detected at batch 3, skipping update...
NaN/Inf gradients detected at batch 10, skipping update...
NaN/Inf gradients detected at batch 24, skipping update...
NaN/Inf gradients detected at batch 30, skipping update...
NaN/Inf gradients detected at batch 32, skipping update...
NaN/Inf gradients detected at batch 38, skipping update...
NaN/Inf gradients detected at batch 49, skipping update...
NaN/Inf gradients detected at batch 56, skipping update...
NaN/Inf gradients detected at batch 60, skipping update...
NaN/Inf gradients detected at batch 65, skipping update...
NaN/Inf gradients detected at batch 70, skipping update...
NaN/Inf gradients detected at batch 73, skipping update...
NaN/Inf gradients detected at batch 75, skipping update...
NaN/Inf gradients detected at batch 78, skipping update...
NaN/Inf gradients detected at batch 81, skipping update...
NaN/Inf gradients detected at batch 83, skipping update...
NaN/Inf gradients detected at batch 86, skipping update...
NaN/Inf gradients detected at batch 87, skipping update...
NaN/Inf gradients detected at batch 95, skipping update...
NaN/Inf gradients detected at batch 98, skipping update...
NaN/Inf gradients detected at batch 103, skipping update...
NaN/Inf gradients detected at batch 120, skipping update...
--------------------
textcnn Epoch 1
total_loss: 1.07149 train_loss: 0.71982 differ_loss: 0.35167 eval_loss: nan
TPR: 0.0 TNR: 100.0 Score: 33.428 Acc: 71.515
PPV: 1 AUC: 0.0 F1: 0.0
NaN/Inf gradients detected at batch 3, skipping update...
NaN/Inf gradients detected at batch 10, skipping update...
NaN/Inf gradients detected at batch 21, skipping update...
NaN/Inf gradients detected at batch 30, skipping update...
NaN/Inf gradients detected at batch 32, skipping update...
NaN/Inf gradients detected at batch 34, skipping update...
NaN/Inf gradients detected at batch 38, skipping update...
NaN/Inf gradients detected at batch 56, skipping update...
NaN/Inf gradients detected at batch 60, skipping update...
NaN/Inf gradients detected at batch 65, skipping update...
NaN/Inf gradients detected at batch 66, skipping update...
NaN/Inf gradients detected at batch 70, skipping update...
NaN/Inf gradients detected at batch 73, skipping update...
NaN/Inf gradients detected at batch 75, skipping update...
NaN/Inf gradients detected at batch 76, skipping update...
NaN/Inf gradients detected at batch 81, skipping update...
NaN/Inf gradients detected at batch 83, skipping update...
NaN/Inf gradients detected at batch 87, skipping update...
NaN/Inf gradients detected at batch 95, skipping update...
NaN/Inf gradients detected at batch 96, skipping update...
NaN/Inf gradients detected at batch 97, skipping update...
NaN/Inf gradients detected at batch 98, skipping update...
NaN/Inf gradients detected at batch 103, skipping update...
NaN/Inf gradients detected at batch 120, skipping update...
--------------------
textcnn Epoch 2
total_loss: 0.8804 train_loss: 0.63755 differ_loss: 0.24285 eval_loss: nan
TPR: 0.0 TNR: 100.0 Score: 33.428 Acc: 71.515
PPV: 1 AUC: 0.0 F1: 0.0
NaN/Inf gradients detected at batch 3, skipping update...
NaN/Inf gradients detected at batch 5, skipping update...
NaN/Inf gradients detected at batch 10, skipping update...
NaN/Inf gradients detected at batch 30, skipping update...
NaN/Inf gradients detected at batch 32, skipping update...
NaN/Inf gradients detected at batch 38, skipping update...
NaN/Inf gradients detected at batch 56, skipping update...
NaN/Inf gradients detected at batch 60, skipping update...
NaN/Inf gradients detected at batch 65, skipping update...
NaN/Inf gradients detected at batch 73, skipping update...
NaN/Inf gradients detected at batch 78, skipping update...
NaN/Inf gradients detected at batch 81, skipping update...
NaN/Inf gradients detected at batch 83, skipping update...
NaN/Inf gradients detected at batch 86, skipping update...
NaN/Inf gradients detected at batch 95, skipping update...
NaN/Inf gradients detected at batch 97, skipping update...
NaN/Inf gradients detected at batch 98, skipping update...
NaN/Inf gradients detected at batch 103, skipping update...
NaN/Inf gradients detected at batch 114, skipping update...
NaN/Inf gradients detected at batch 120, skipping update...
--------------------
textcnn Epoch 3
total_loss: 0.79259 train_loss: 0.58877 differ_loss: 0.20382 eval_loss: nan
TPR: 0.0 TNR: 100.0 Score: 33.428 Acc: 71.515
PPV: 1 AUC: 0.0 F1: 0.0
NaN/Inf gradients detected at batch 3, skipping update...
NaN/Inf gradients detected at batch 10, skipping update...
NaN/Inf gradients detected at batch 30, skipping update...
NaN/Inf gradients detected at batch 32, skipping update...
NaN/Inf gradients detected at batch 34, skipping update...
NaN/Inf gradients detected at batch 38, skipping update...
NaN/Inf gradients detected at batch 49, skipping update...
NaN/Inf gradients detected at batch 60, skipping update...
NaN/Inf gradients detected at batch 65, skipping update...
NaN/Inf gradients detected at batch 70, skipping update...
NaN/Inf gradients detected at batch 73, skipping update...
NaN/Inf gradients detected at batch 81, skipping update...
NaN/Inf gradients detected at batch 83, skipping update...
NaN/Inf gradients detected at batch 86, skipping update...
NaN/Inf gradients detected at batch 95, skipping update...
NaN/Inf gradients detected at batch 97, skipping update...
NaN/Inf gradients detected at batch 103, skipping update...
NaN/Inf gradients detected at batch 114, skipping update...
--------------------
textcnn Epoch 4
total_loss: 0.77473 train_loss: 0.56922 differ_loss: 0.20551 eval_loss: nan
TPR: 0.0 TNR: 100.0 Score: 33.428 Acc: 71.515
PPV: 1 AUC: 0.0 F1: 0.0
NaN/Inf gradients detected at batch 3, skipping update...
NaN/Inf gradients detected at batch 10, skipping update...
NaN/Inf gradients detected at batch 27, skipping update...
NaN/Inf gradients detected at batch 30, skipping update...
NaN/Inf gradients detected at batch 32, skipping update...
NaN/Inf gradients detected at batch 52, skipping update...
NaN/Inf gradients detected at batch 56, skipping update...
NaN/Inf gradients detected at batch 60, skipping update...
NaN/Inf gradients detected at batch 65, skipping update...
NaN/Inf gradients detected at batch 66, skipping update...
NaN/Inf gradients detected at batch 70, skipping update...
NaN/Inf gradients detected at batch 73, skipping update...
NaN/Inf gradients detected at batch 78, skipping update...
NaN/Inf gradients detected at batch 81, skipping update...
NaN/Inf gradients detected at batch 83, skipping update...
NaN/Inf gradients detected at batch 86, skipping update...
NaN/Inf gradients detected at batch 97, skipping update...
NaN/Inf gradients detected at batch 98, skipping update...
NaN/Inf gradients detected at batch 103, skipping update...
NaN/Inf gradients detected at batch 114, skipping update...
NaN/Inf gradients detected at batch 120, skipping update...
--------------------
textcnn Epoch 5
total_loss: 0.72547 train_loss: 0.54759 differ_loss: 0.17788 eval_loss: nan
TPR: 0.0 TNR: 100.0 Score: 33.428 Acc: 71.515
PPV: 1 AUC: 0.0 F1: 0.0
NaN/Inf gradients detected at batch 3, skipping update...
NaN/Inf gradients detected at batch 10, skipping update...
NaN/Inf gradients detected at batch 21, skipping update...
NaN/Inf gradients detected at batch 30, skipping update...
NaN/Inf gradients detected at batch 32, skipping update...
NaN/Inf gradients detected at batch 34, skipping update...
NaN/Inf gradients detected at batch 38, skipping update...
NaN/Inf gradients detected at batch 49, skipping update...
NaN/Inf gradients detected at batch 56, skipping update...
NaN/Inf gradients detected at batch 60, skipping update...
NaN/Inf gradients detected at batch 65, skipping update...
NaN/Inf gradients detected at batch 66, skipping update...
NaN/Inf gradients detected at batch 73, skipping update...
NaN/Inf gradients detected at batch 75, skipping update...
NaN/Inf gradients detected at batch 76, skipping update...
NaN/Inf gradients detected at batch 78, skipping update...
NaN/Inf gradients detected at batch 81, skipping update...
NaN/Inf gradients detected at batch 83, skipping update...
NaN/Inf gradients detected at batch 86, skipping update...
NaN/Inf gradients detected at batch 87, skipping update...
NaN/Inf gradients detected at batch 97, skipping update...
NaN/Inf gradients detected at batch 98, skipping update...
NaN/Inf gradients detected at batch 103, skipping update...
NaN/Inf gradients detected at batch 120, skipping update...
--------------------
textcnn Epoch 6
total_loss: 0.70787 train_loss: 0.53713 differ_loss: 0.17074 eval_loss: nan
TPR: 0.0 TNR: 100.0 Score: 33.428 Acc: 71.515
PPV: 1 AUC: 0.0 F1: 0.0
NaN/Inf gradients detected at batch 3, skipping update...
NaN/Inf gradients detected at batch 5, skipping update...
NaN/Inf gradients detected at batch 10, skipping update...
NaN/Inf gradients detected at batch 24, skipping update...
NaN/Inf gradients detected at batch 30, skipping update...
NaN/Inf gradients detected at batch 32, skipping update...
NaN/Inf gradients detected at batch 34, skipping update...
NaN/Inf gradients detected at batch 38, skipping update...
NaN/Inf gradients detected at batch 56, skipping update...
NaN/Inf gradients detected at batch 60, skipping update...
NaN/Inf gradients detected at batch 65, skipping update...
NaN/Inf gradients detected at batch 73, skipping update...
NaN/Inf gradients detected at batch 75, skipping update...
NaN/Inf gradients detected at batch 78, skipping update...
NaN/Inf gradients detected at batch 81, skipping update...
NaN/Inf gradients detected at batch 83, skipping update...
NaN/Inf gradients detected at batch 86, skipping update...
NaN/Inf gradients detected at batch 95, skipping update...
NaN/Inf gradients detected at batch 97, skipping update...
NaN/Inf gradients detected at batch 98, skipping update...
NaN/Inf gradients detected at batch 103, skipping update...
NaN/Inf gradients detected at batch 120, skipping update...
--------------------
textcnn Epoch 7
total_loss: 0.68758 train_loss: 0.52254 differ_loss: 0.16503 eval_loss: nan
TPR: 0.0 TNR: 100.0 Score: 33.428 Acc: 71.515
PPV: 1 AUC: 0.0 F1: 0.0
NaN/Inf gradients detected at batch 3, skipping update...
NaN/Inf gradients detected at batch 5, skipping update...
NaN/Inf gradients detected at batch 10, skipping update...
NaN/Inf gradients detected at batch 30, skipping update...
NaN/Inf gradients detected at batch 32, skipping update...
NaN/Inf gradients detected at batch 34, skipping update...
NaN/Inf gradients detected at batch 38, skipping update...
NaN/Inf gradients detected at batch 60, skipping update...
NaN/Inf gradients detected at batch 65, skipping update...
NaN/Inf gradients detected at batch 66, skipping update...
NaN/Inf gradients detected at batch 70, skipping update...
NaN/Inf gradients detected at batch 73, skipping update...
NaN/Inf gradients detected at batch 75, skipping update...
NaN/Inf gradients detected at batch 78, skipping update...
NaN/Inf gradients detected at batch 81, skipping update...
NaN/Inf gradients detected at batch 83, skipping update...
NaN/Inf gradients detected at batch 86, skipping update...
NaN/Inf gradients detected at batch 97, skipping update...
NaN/Inf gradients detected at batch 98, skipping update...
NaN/Inf gradients detected at batch 103, skipping update...
--------------------
textcnn Epoch 8
total_loss: 0.66988 train_loss: 0.51216 differ_loss: 0.15772 eval_loss: nan
TPR: 0.0 TNR: 100.0 Score: 33.428 Acc: 71.515
PPV: 1 AUC: 0.0 F1: 0.0
NaN/Inf gradients detected at batch 3, skipping update...
NaN/Inf gradients detected at batch 10, skipping update...
NaN/Inf gradients detected at batch 30, skipping update...
NaN/Inf gradients detected at batch 32, skipping update...
NaN/Inf gradients detected at batch 34, skipping update...
NaN/Inf gradients detected at batch 38, skipping update...
NaN/Inf gradients detected at batch 56, skipping update...
NaN/Inf gradients detected at batch 60, skipping update...
NaN/Inf gradients detected at batch 65, skipping update...
NaN/Inf gradients detected at batch 70, skipping update...
NaN/Inf gradients detected at batch 73, skipping update...
NaN/Inf gradients detected at batch 78, skipping update...
NaN/Inf gradients detected at batch 81, skipping update...
NaN/Inf gradients detected at batch 83, skipping update...
NaN/Inf gradients detected at batch 86, skipping update...
NaN/Inf gradients detected at batch 97, skipping update...
NaN/Inf gradients detected at batch 98, skipping update...
NaN/Inf gradients detected at batch 103, skipping update...
--------------------
textcnn Epoch 9
total_loss: 0.66328 train_loss: 0.50753 differ_loss: 0.15575 eval_loss: nan
TPR: 0.0 TNR: 100.0 Score: 33.428 Acc: 71.515
PPV: 1 AUC: 0.0 F1: 0.0
NaN/Inf gradients detected at batch 3, skipping update...
NaN/Inf gradients detected at batch 10, skipping update...
NaN/Inf gradients detected at batch 18, skipping update...
NaN/Inf gradients detected at batch 30, skipping update...
NaN/Inf gradients detected at batch 32, skipping update...
NaN/Inf gradients detected at batch 34, skipping update...
NaN/Inf gradients detected at batch 38, skipping update...
NaN/Inf gradients detected at batch 49, skipping update...
NaN/Inf gradients detected at batch 56, skipping update...
NaN/Inf gradients detected at batch 60, skipping update...
NaN/Inf gradients detected at batch 65, skipping update...
NaN/Inf gradients detected at batch 70, skipping update...
NaN/Inf gradients detected at batch 73, skipping update...
NaN/Inf gradients detected at batch 78, skipping update...
NaN/Inf gradients detected at batch 81, skipping update...
NaN/Inf gradients detected at batch 83, skipping update...
NaN/Inf gradients detected at batch 86, skipping update...
NaN/Inf gradients detected at batch 95, skipping update...
NaN/Inf gradients detected at batch 96, skipping update...
NaN/Inf gradients detected at batch 97, skipping update...
NaN/Inf gradients detected at batch 98, skipping update...
NaN/Inf gradients detected at batch 103, skipping update...
--------------------
textcnn Epoch 10
total_loss: 0.64605 train_loss: 0.50001 differ_loss: 0.14605 eval_loss: nan
TPR: 0.0 TNR: 100.0 Score: 33.428 Acc: 71.515
PPV: 1 AUC: 0.0 F1: 0.0
final_test
TPR: 0.0 TNR: 100.0 Score: 33.495 Acc: 0.716
PPV: 1 AUC: 0.0 F1: 0.0 SEN: 0.0 SPEC: 1.0
